{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Election for Single Criterion Recommender System\n",
    "\n",
    "## 1. Selection of the algorithm\n",
    "\n",
    "Let's use the structure on https://github.com/NicolasHug/Surprise/blob/master/examples/benchmark.py to evaluate different algorithms to use on the recommender system with the data we have.\n",
    "\n",
    "In any case I want to compare item-based and user-based approaches when possible. I believe SVD does not allow for such.\n",
    "\n",
    "Once I have done that, I will implement that specific one on the recommender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import six\n",
    "from tabulate import tabulate\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is **user-based**, if we want **item-based** we need to specify the parameter to be false.\n",
    "\n",
    "The default similarity is **MSD**.\n",
    "\n",
    "Let's look at cross-validation performance first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "\n",
      "\n",
      " User-based recommenders \n",
      "\n",
      "| Name            |   RMSE |   MAE |   FCP | Time    |\n",
      "|:----------------|-------:|------:|------:|:--------|\n",
      "| SVD             |  0.549 | 0.417 | 0.523 | 0:00:03 |\n",
      "| SVD++           |  0.536 | 0.408 | 0.526 | 0:00:11 |\n",
      "| NMF             |  0.62  | 0.46  | 0.525 | 0:00:04 |\n",
      "| SlopeOne        |  0.671 | 0.459 | 0.468 | 0:00:00 |\n",
      "| KNNBasic        |  0.616 | 0.436 | 0.491 | 0:00:00 |\n",
      "| KNNWithMeans    |  0.667 | 0.483 | 0.48  | 0:00:01 |\n",
      "| KNNBaseline     |  0.538 | 0.398 | 0.526 | 0:00:00 |\n",
      "| CoClustering    |  0.763 | 0.582 | 0.515 | 0:00:03 |\n",
      "| BaselineOnly    |  0.599 | 0.448 | 0.521 | 0:00:00 |\n",
      "| NormalPredictor |  1.13  | 0.898 | 0.504 | 0:00:00 |\n"
     ]
    }
   ],
   "source": [
    "classes = {'SVD':SVD, 'SVD++':SVDpp, 'NMF':NMF, 'SlopeOne':SlopeOne, 'KNNBasic':KNNBasic, 'KNNWithMeans':KNNWithMeans, \n",
    "           'KNNBaseline':KNNBaseline,'CoClustering':CoClustering, 'BaselineOnly':BaselineOnly, \n",
    "           'NormalPredictor':NormalPredictor}\n",
    "\n",
    "# set RNG\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "\n",
    "for name, klass in classes.items():\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass(), data, ['rmse', 'mae', 'fcp'], kf, verbose=False)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "    mean_fcp = '{:.3f}'.format(np.mean(out['test_fcp']))\n",
    "    \n",
    "    new_line = [name, mean_rmse, mean_mae, mean_fcp, cv_time]\n",
    "    table.append(new_line)\n",
    "print('\\n\\n User-based recommenders \\n')\n",
    "header = ['Name',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'FCP',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the performance on unseen data by splitting the dataset and retraining everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD\n",
      "RMSE: 0.5647\n",
      "MAE:  0.4256\n",
      "FCP:  0.5378\n",
      "SVD++\n",
      "RMSE: 0.5512\n",
      "MAE:  0.4158\n",
      "FCP:  0.5321\n",
      "NMF\n",
      "RMSE: 0.6318\n",
      "MAE:  0.4690\n",
      "FCP:  0.5375\n",
      "SlopeOne\n",
      "RMSE: 0.6945\n",
      "MAE:  0.4665\n",
      "FCP:  0.4245\n",
      "KNNBasic\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.6227\n",
      "MAE:  0.4335\n",
      "FCP:  0.4537\n",
      "KNNWithMeans\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.6987\n",
      "MAE:  0.4965\n",
      "FCP:  0.4654\n",
      "KNNBaseline\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.5450\n",
      "MAE:  0.3979\n",
      "FCP:  0.5284\n",
      "CoClustering\n",
      "RMSE: 0.7977\n",
      "MAE:  0.6254\n",
      "FCP:  0.5245\n",
      "BaselineOnly\n",
      "Estimating biases using als...\n",
      "RMSE: 0.6190\n",
      "MAE:  0.4580\n",
      "FCP:  0.5336\n",
      "NormalPredictor\n",
      "RMSE: 1.1388\n",
      "MAE:  0.8968\n",
      "FCP:  0.4906\n",
      "\n",
      "\n",
      " User-based recommenders \n",
      "\n",
      "| Name            |   RMSE |   MAE |   FCP | Time    |\n",
      "|:----------------|-------:|------:|------:|:--------|\n",
      "| SVD             |  0.565 | 0.426 | 0.538 | 0:00:00 |\n",
      "| SVD++           |  0.551 | 0.416 | 0.532 | 0:00:02 |\n",
      "| NMF             |  0.632 | 0.469 | 0.538 | 0:00:00 |\n",
      "| SlopeOne        |  0.695 | 0.466 | 0.425 | 0:00:00 |\n",
      "| KNNBasic        |  0.623 | 0.434 | 0.454 | 0:00:00 |\n",
      "| KNNWithMeans    |  0.699 | 0.496 | 0.465 | 0:00:00 |\n",
      "| KNNBaseline     |  0.545 | 0.398 | 0.528 | 0:00:00 |\n",
      "| CoClustering    |  0.798 | 0.625 | 0.525 | 0:00:00 |\n",
      "| BaselineOnly    |  0.619 | 0.458 | 0.534 | 0:00:00 |\n",
      "| NormalPredictor |  1.139 | 0.897 | 0.491 | 0:00:00 |\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "classes2 = {'SVD':SVD(), 'SVD++':SVDpp(), 'NMF':NMF(), 'SlopeOne':SlopeOne(), 'KNNBasic':KNNBasic(), 'KNNWithMeans':KNNWithMeans(), \n",
    "           'KNNBaseline':KNNBaseline(),'CoClustering':CoClustering(), 'BaselineOnly':BaselineOnly(), \n",
    "           'NormalPredictor':NormalPredictor()}\n",
    "\n",
    "table = []\n",
    "\n",
    "for name, klass in classes2.items():\n",
    "    print(name)\n",
    "    start = time.time()\n",
    "    klass.fit(trainset)\n",
    "    predictions = klass.test(testset)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    \n",
    "    mean_rmse = '{:.3f}'.format(accuracy.rmse(predictions))\n",
    "    mean_mae = '{:.3f}'.format(accuracy.mae(predictions))\n",
    "    mean_fcp = '{:.3f}'.format(accuracy.fcp(predictions))\n",
    "    \n",
    "    new_line = [name, mean_rmse, mean_mae, mean_fcp, cv_time]\n",
    "    table.append(new_line)\n",
    "print('\\n\\n User-based recommenders \\n')\n",
    "header = ['Name',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'FCP',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it is still KNN baseline the best performing one. There doesn't seem to be overfit anywhere since the RMSE and MAEs are slightly larger than using cross-validation. SVD++ is the slowest one, and due to the small sample size, none of the others have an appreciable runtime.\n",
    "\n",
    "Now, we can look at item-based algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "\n",
      " Item-based recommenders \n",
      "\n",
      "| Name         |   RMSE |   MAE |   FCP | Time    |\n",
      "|:-------------|-------:|------:|------:|:--------|\n",
      "| KNNBasic     |  0.668 | 0.468 | 0.472 | 0:00:00 |\n",
      "| KNNWithMeans |  0.529 | 0.39  | 0.52  | 0:00:00 |\n",
      "| KNNBaseline  |  0.564 | 0.413 | 0.519 | 0:00:00 |\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'name': 'msd', 'user_based': False}\n",
    "classes = {'KNNBasic':KNNBasic(sim_options=sim_options), \n",
    "           'KNNWithMeans':KNNWithMeans(sim_options=sim_options), \n",
    "           'KNNBaseline':KNNBaseline(sim_options=sim_options)}\n",
    "# these are the only ones that accept the options. The others don't... :( \n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "\n",
    "for name, klass in classes.items():\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass, data, ['rmse', 'mae', 'fcp'], kf, verbose=False)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "    mean_fcp = '{:.3f}'.format(np.mean(out['test_fcp']))\n",
    "    \n",
    "    new_line = [name, mean_rmse, mean_mae, mean_fcp, cv_time]\n",
    "    table.append(new_line)\n",
    "print('\\n\\n Item-based recommenders \\n')\n",
    "header = ['Name',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'FCP',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, it seems that KNN Baseline performs a bit better. Even though we cannot see a delay in run time, it is more expensive to go item-based, so we may want to avoid it.\n",
    "\n",
    "How about another similarity? And other parameters on KNN? Let's see if we observe any difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "\n",
      " Item-based recommenders \n",
      "\n",
      "| Name         |   RMSE |   MAE |   FCP | Time    |\n",
      "|:-------------|-------:|------:|------:|:--------|\n",
      "| KNNBasic     |  0.616 | 0.436 | 0.491 | 0:00:00 |\n",
      "| KNNWithMeans |  0.667 | 0.483 | 0.48  | 0:00:01 |\n",
      "| KNNBaseline  |  0.538 | 0.398 | 0.526 | 0:00:00 |\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'name': 'msd'}\n",
    "classes = {'KNNBasic':KNNBasic(sim_options=sim_options), \n",
    "           'KNNWithMeans':KNNWithMeans(sim_options=sim_options), \n",
    "           'KNNBaseline':KNNBaseline(sim_options=sim_options)}\n",
    "\n",
    "# set RNG\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FIRST ATTEMPT/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "\n",
    "for name, klass in classes.items():\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass, data, ['rmse', 'mae', 'fcp'], kf, verbose=False)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "    mean_fcp = '{:.3f}'.format(np.mean(out['test_fcp']))\n",
    "    \n",
    "    new_line = [name, mean_rmse, mean_mae, mean_fcp, cv_time]\n",
    "    table.append(new_line)\n",
    "print('\\n\\n Item-based recommenders \\n')\n",
    "header = ['Name',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'FCP',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433716300066304\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD doesn't seem to be able to improve KNNBaseline ever. So we will go ahead and use it from now on.\n",
    "\n",
    "For the deployment, we want to run the codes on demand, so the next section describes how this is doen and has some results\n",
    "\n",
    "***\n",
    "\n",
    "## 2. Example of implementation\n",
    "\n",
    "Before we get hands on, a few considerations:\n",
    "\n",
    "* for an existing user with some ratings, what would it be the best hotels? How do we do that?\n",
    "* what are similar hotels to a specific one?\n",
    "* What if a user doesn't have any ratings? Should we just add the most popular hotels for the area?\n",
    "\n",
    "Let's start again by training the algorithm. Then, I will chose both: user with ratings and user without ratings, and will look at the output. Finally, let's try to look at hotels similar to a specific one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "\n",
      "Top 10 hotels for user 3 :\n",
      "blue moon hotel : 5\n",
      "homewood suites las vegas airport : 5\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.996907332713799\n",
      "comfort inn midtown manhattan : 4.996907332713798\n",
      "allerton hotel : 4.9849054020480885\n",
      "serrano hotel a kimpton hotel : 4.9574337074161665\n",
      "four seasons hotel san francisco : 4.948217391789254\n",
      "the bowery hotel : 4.937430263528778\n",
      "hotel vitale : 4.937430263528778\n",
      "the peninsula chicago : 4.933398035411475\n",
      "\n",
      "\n",
      "Top 10 hotels for user 3  (item-based):\n",
      "kitano new york : 5\n",
      "best western hospitality house : 4.920003316334549\n",
      "omni san francisco hotel : 4.842450737561286\n",
      "columbus motor inn : 4.82953612873261\n",
      "plaza athenee hotel : 4.692137807975122\n",
      "hilton club new york : 4.669006284896156\n",
      "w san francisco : 4.5849234535079315\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.50245750656698\n",
      "courtyard new york manhattan midtown east : 4.458656265040781\n",
      "the talbott hotel : 4.456145034966841\n",
      "\n",
      "\n",
      "Top 10 hotels for user 2000  (who has no reviews whatsoever):\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.509093004901597\n",
      "courtyard new york manhattan midtown east : 4.465291763375398\n",
      "the talbott hotel : 4.4627805333014585\n",
      "the mark : 4.460600367487\n",
      "carlton inn midway : 4.456871255400621\n",
      "hampton inn majestic chicago : 4.431775011894604\n",
      "the hampton inn times square north : 4.430601100429042\n",
      "springhill suites chicago downtown river north : 4.424402550903542\n",
      "the blakely new york : 4.412183320157887\n",
      "four seasons hotel las vegas : 4.411622117604449\n",
      "\n",
      "\n",
      "Top 10 hotels for user 2100  (who has no reviews whatsoever either):\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.509093004901597\n",
      "courtyard new york manhattan midtown east : 4.465291763375398\n",
      "the talbott hotel : 4.4627805333014585\n",
      "the mark : 4.460600367487\n",
      "carlton inn midway : 4.456871255400621\n",
      "hampton inn majestic chicago : 4.431775011894604\n",
      "the hampton inn times square north : 4.430601100429042\n",
      "springhill suites chicago downtown river north : 4.424402550903542\n",
      "the blakely new york : 4.412183320157887\n",
      "four seasons hotel las vegas : 4.411622117604449\n",
      "\n",
      "\n",
      "Top 10 hotels for user 2100  (who has no reviews whatsoever either)(item-based):\n",
      "holiday inn express hotel and suites las vegas 215 beltway : 4.509093004901597\n",
      "courtyard new york manhattan midtown east : 4.465291763375398\n",
      "the talbott hotel : 4.4627805333014585\n",
      "the mark : 4.460600367487\n",
      "carlton inn midway : 4.456871255400621\n",
      "hampton inn majestic chicago : 4.431775011894604\n",
      "the hampton inn times square north : 4.430601100429042\n",
      "springhill suites chicago downtown river north : 4.424402550903542\n",
      "the blakely new york : 4.412183320157887\n",
      "four seasons hotel las vegas : 4.411622117604449\n"
     ]
    }
   ],
   "source": [
    "# import specific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "# read data\n",
    "file_path = os.path.expanduser('/home/jonas/Desktop/SpringBoard_Capstone_1/FINALE/generated_ratings_1_reduced.csv')\n",
    "reader = Reader(line_format='item rating user', sep=',')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "# train kNN-Baseline on the whole collection (both, user and item-wise)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build an algorithm, and train it.\n",
    "algo = KNNBaseline()\n",
    "algo.fit(trainset)\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "algo_items = KNNBaseline(sim_options=sim_options)\n",
    "algo_items.fit(trainset)\n",
    "\n",
    "######################################################################\n",
    "# Best hotels for user XX\n",
    "# list of hotels...\n",
    "hoteldf = pd.read_csv('/home/jonas/Desktop/SpringBoard_Capstone_1/FINALE/generated_ratings_1_reduced.csv', header=None, names=['item', 'rating','user'])\n",
    "hotels = hoteldf['item'].unique().tolist()\n",
    "\n",
    "# case 1\n",
    "user1 = '3'\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo.predict(user1, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user1, ':')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])\n",
    "    \n",
    "# case 1.5\n",
    "user1 = '3'\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo_items.predict(user1, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user1, ' (item-based):')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])\n",
    "    \n",
    "# case 2\n",
    "user2 = '2000' # there's 1789 users with ratings...\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo.predict(user2, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user2, ' (who has no reviews whatsoever):')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])\n",
    "    \n",
    "# case 3\n",
    "user2 = '2100' # there's 1789 users with ratings...\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo.predict(user2, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user2, ' (who has no reviews whatsoever either):')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])\n",
    "    \n",
    "# case 3.5\n",
    "user2 = '2100' # there's 1789 users with ratings...\n",
    "hot_ratings_user = {}\n",
    "# loop to find ratings\n",
    "for hot in hotels:\n",
    "    pred = algo_items.predict(user2, hot)\n",
    "    hot_ratings_user[hot] = pred.est\n",
    "# the whole dictionary should be done now... I want the top N = 10\n",
    "print('\\n\\nTop 10 hotels for user', user2, ' (who has no reviews whatsoever either)(item-based):')\n",
    "sorted_hot_ratings_user = sorted(hot_ratings_user, key=hot_ratings_user.get, reverse=True)[:10]\n",
    "for key in sorted_hot_ratings_user:\n",
    "    print(key, ':', hot_ratings_user[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the kimberly hotel\n",
      "sofitel chicago water tower\n",
      "the peninsula chicago\n",
      "lowell hotel\n",
      "the plaza\n",
      "the gem hotel chelsea\n",
      "greenwich hotel\n",
      "sofitel new york\n",
      "the carlyle a rosewood hotel\n",
      "the ritz carlton\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Hotels similar to XX\n",
    "hotel = 'courtyard by marriott new york manhattan upper east side'\n",
    "\n",
    "# need to convert hotel to id\n",
    "h_inner_id = algo.trainset.to_inner_iid(hotel)\n",
    "\n",
    "# neigbouring ids\n",
    "hotel_neighbors = algo_items.get_neighbors(h_inner_id, k=10)\n",
    "\n",
    "# take them back to names\n",
    "hotel_neighbors = (algo_items.trainset.to_raw_iid(inner_id) for inner_id in hotel_neighbors)\n",
    "\n",
    "# boom\n",
    "for hotl in hotel_neighbors:\n",
    "    print(hotl)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9277b1c13699449dae06c90bea48c071",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most popular hotels? From original dataset, we want the higest average given a minimum number of ratings\n",
    "\n",
    "raw = pd.read_csv('manually_corrected_data/Hotels_clean_merged.csv')\n",
    "\n",
    "city = 'san francisco'\n",
    "sfo = raw[raw['city']==city]\n",
    "sfo = sfo[sfo['num_reviews']>9]\n",
    "sfo_sprted = sfo.sort_values(by='overall_ratingsource', axis=0, ascending=False)\n",
    "sfo_sprted = sfo_sprted.head(10)\n",
    "sfo_sprted\n",
    "# sfo_sprted['hotel_name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes seem to work well. For an existing user we can do some recommendations, for new users the recomendations are default. We can see similar hotels to existing ones (maybe there's room for improvement there, but we'd need better data), as well as the best hotels by city.\n",
    "\n",
    "### Future considerations\n",
    "\n",
    "Additional improvements are out of scope, but here's a very interesting option: using a multicriteria recommender system. That requires working on the core code instead of using existing packages, but it is rather easy, and can possibly make a big difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
